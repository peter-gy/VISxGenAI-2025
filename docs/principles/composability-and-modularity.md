---
aside: false
---

# ðŸ§© Composability & Modularity

Instead of embedding all logic in language models, we move critical tasks to specialized, deterministic components. This makes the system more transparent, auditable, and fixable.

Two key components handle data truth and visualization design. The **Dataset Profiler** computes statistical profiles programmaticallyâ€”means, distributions, correlations. This statistical truth lives outside the LLM, giving other agents reliable data to work with. When the **Insight Planner** needs to understand what's in the data, it queries this profile rather than guessing.

For visualization, we use [Draco](https://github.com/cmudig/draco2), a rule-based solver. Traditional LLM chart design is expensive, inconsistent, and hard to debug. Draco works differently. It takes metadata about what to show and decides how to show it using explicit rules. Want to visualize sales by region? Draco analyzes the data propertiesâ€”cardinality, skew, data typesâ€”and picks the right chart.

This split is powerful. LLMs handle the "what" (which insights matter), while Draco handles the "how" (which charts work). When Draco makes a poor choice, we can trace why and fix the rules. This creates lasting improvements, not fragile prompt tweaks.

The approach scales well. Statistical profiling stays accurate regardless of dataset size. Draco's rules improve over time. And both components work independently of the LLMs, making the whole system more reliable and easier to maintain.

For a concrete example, see our [case study](../gallery/vispub-flawed-insight) on how we used this approach to improve the quality of insights generated by the system.